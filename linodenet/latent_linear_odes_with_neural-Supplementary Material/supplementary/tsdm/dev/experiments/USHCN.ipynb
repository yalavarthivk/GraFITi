{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc22d517-c76d-4da2-ac57-ab077be3396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c03d7-324c-4bc8-ae50-5392d4ff4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# enable JIT compilation - must be done before loading torch!\n",
    "os.environ[\"PYTORCH_JIT\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1c36b-b316-486d-bf09-724a98b0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdm\n",
    "import torch\n",
    "import pandas\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "from torch import tensor, Tensor, jit\n",
    "from torch.utils.data import BatchSampler, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tsdm.metrics import LOSSES\n",
    "from tsdm.utils import grad_norm, multi_norm\n",
    "from tsdm.datasets import Electricity\n",
    "from tsdm.encoders import time2float\n",
    "\n",
    "from linodenet.models import LinODEnet, LinODECell, LinODE\n",
    "from linodenet.projections import symmetric, skew_symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccb53e-8b33-45be-902f-575f1ed5afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "DTYPE = torch.float32\n",
    "NAN = tensor(float(\"nan\"), dtype=DTYPE, device=DEVICE)\n",
    "BATCH_SIZE = 16\n",
    "PRD_HORIZON = 24\n",
    "OBS_HORIZON = 96\n",
    "SEQLEN = PRD_HORIZON + OBS_HORIZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32106a95-81de-4df2-872a-4fd60272c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.tasks import ETDatasetInformer\n",
    "\n",
    "TASK = ETDatasetInformer(\n",
    "    dataset=\"ETTm1\",\n",
    "    forecasting_horizon=24,\n",
    "    observation_horizon=96,\n",
    "    test_metric=\"MSE\",\n",
    "    time_encoder=\"time2float\",\n",
    ")\n",
    "DATASET = TASK.dataset\n",
    "\n",
    "NUM_PTS, NUM_DIM = DATASET.dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e8ab3-a104-4492-b68a-d7f67e739921",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20388705-69a4-4765-bde4-d27527def516",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit.script\n",
    "def prep_batch(batch: tuple[Tensor, Tensor, Tensor], observation_horizon: int):\n",
    "    T, X, Y = batch\n",
    "    targets = Y[..., observation_horizon:].clone()\n",
    "    Y[..., observation_horizon:] = float(\"nan\")  # mask future\n",
    "    X[..., observation_horizon:, :] = float(\"nan\")  # mask future\n",
    "    inputs = torch.cat([X, Y.unsqueeze(-1)], dim=-1)\n",
    "    return T, inputs, targets\n",
    "\n",
    "\n",
    "def get_all_preds(model, dataloader):\n",
    "    Y, Ŷ = [], []\n",
    "    for batch in tqdm(dataloader, leave=False):\n",
    "        with torch.no_grad():\n",
    "            model.zero_grad()\n",
    "            times, inputs, targets = prep_batch(batch, OBS_HORIZON)\n",
    "            outputs, _ = model(times, inputs)\n",
    "            predics = outputs[:, OBS_HORIZON:, -1]\n",
    "            loss = LOSS(predics, targets)\n",
    "            Y.append(targets)\n",
    "            Ŷ.append(predics)\n",
    "\n",
    "    return torch.cat(Y, dim=0), torch.cat(Ŷ, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5892b9-c3ad-4b3b-992e-e082b600227c",
   "metadata": {},
   "source": [
    "# logging utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2919d5f-1d1f-4147-aacf-3e50d09230ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_all(i, model, writer, optimizer):\n",
    "    kernel = model.system.kernel.clone().detach().cpu()\n",
    "    log_kernel_information(i, writer, kernel, histograms=True)\n",
    "    log_optimizer_state(i, writer, optimizer, histograms=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe5c80-2903-4964-a647-ca2dd343f959",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plotting Kernel Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3db39e-34df-40e3-a7fb-0769b7f135a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from linodenet.models import LinODEnet\n",
    "from tsdm.utils.logging import (\n",
    "    log_optimizer_state,\n",
    "    log_kernel_information,\n",
    "    log_model_state,\n",
    "    log_metrics,\n",
    ")\n",
    "\n",
    "MODEL = LinODEnet\n",
    "model = MODEL(input_size=NUM_DIM, hidden_size=32, embedding_type=\"concat\")\n",
    "model.to(device=DEVICE, dtype=DTYPE)\n",
    "LOSS = TASK.test_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f560c2e-7842-4a42-905f-0abf73af7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "# dataloader for training\n",
    "TRAINLOADER = TASK.get_dataloader(\"train\", batch_size=64)\n",
    "# dataloaders for evaluation\n",
    "eval_loaders = {\n",
    "    split: TASK.get_dataloader(split, batch_size=1024, shuffle=False)\n",
    "    for split in (\"train\", \"valid\", \"test\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6298fa-fd88-4191-9864-2cc58f73f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup - set all gradients to none\n",
    "y, yhat = model(torch.randn(NUM_DIM).cuda(), torch.randn(1, NUM_DIM).cuda())\n",
    "torch.linalg.norm(y).backward()\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d718219-e9f8-469b-827b-468c9dca0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_START = tsdm.utils.now()\n",
    "CHECKPOINTDIR = Path(f\"checkpoints/{RUN_START}/\")\n",
    "CHECKPOINTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "writer = SummaryWriter(f\"runs/{MODEL.__name__}/{DATASET.__name__}{RUN_START}\")\n",
    "metrics = {key: LOSSES[key] for key in (\"ND\", \"NRMSE\", \"MSE\", \"MAE\")}\n",
    "assert TASK.test_metric in metrics.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9b5c3-8da4-4e5b-b4a5-f0dfac9ff450",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "\n",
    "for epoch in (epochs := trange(100)):\n",
    "    # log\n",
    "    with torch.no_grad():\n",
    "        # log optimizer state first !!!\n",
    "        log_optimizer_state(epoch, writer, optimizer, histograms=True)\n",
    "        log_kernel_information(epoch, writer, model.system.kernel, histograms=True)\n",
    "\n",
    "        for name, dataloader in eval_loaders.items():\n",
    "            y, ŷ = get_all_preds(model, dataloader)\n",
    "            log_metrics(epoch, writer, y, ŷ, metrics, prefix=name)\n",
    "\n",
    "    for batch in (batches := tqdm(TRAINLOADER)):\n",
    "        i += 1\n",
    "        # Optimization step\n",
    "        model.zero_grad()\n",
    "        times, inputs, targets = prep_batch(batch, OBS_HORIZON)\n",
    "        outputs, _ = model(times, inputs)\n",
    "        predics = outputs[:, OBS_HORIZON:, -1]\n",
    "        loss = LOSS(predics, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # batch logging\n",
    "        with torch.no_grad():\n",
    "            i += 1\n",
    "            log_metrics(i, writer, targets, predics, metrics, prefix=\"batch\")\n",
    "            log_optimizer_state(i, writer, optimizer, prefix=\"batch\")\n",
    "\n",
    "            lval = loss.clone().detach().cpu().numpy()\n",
    "            gval = grad_norm(list(model.parameters())).clone().detach().cpu().numpy()\n",
    "            batches.set_postfix(loss=lval, gnorm=gval)\n",
    "\n",
    "            if torch.any(torch.isnan(loss)):\n",
    "                raise RuntimeError(\"NaN-value encountered!!\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # log optimizer state first !!!\n",
    "        log_optimizer_state(epoch, writer, optimizer, histograms=True)\n",
    "        log_kernel_information(epoch, writer, model.system.kernel, histograms=True)\n",
    "\n",
    "        for name, dataloader in eval_loaders.items():\n",
    "            y, ŷ = get_all_preds(model, dataloader)\n",
    "            log_metrics(epoch, writer, y, ŷ, metrics, prefix=name)\n",
    "\n",
    "        # Model Checkpoint\n",
    "        torch.jit.save(model, CHECKPOINTDIR.joinpath(f\"{MODEL.__name__}-{epochs.n}\"))\n",
    "        torch.save(\n",
    "            {\n",
    "                \"optimizer\": optimizer,\n",
    "                \"epoch\": epoch,\n",
    "                \"batch\": i,\n",
    "            },\n",
    "            CHECKPOINTDIR.joinpath(f\"{optimizer.__class__.__name__}-{epochs.n}\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08247a3b-fff0-4111-86f8-840ce239a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard as tb\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9131876-0c87-432a-9724-1a14b4d4f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ea = EventAccumulator(\n",
    "    \"/home/rscholz/Projects/KIWI/tsdm/dev/experiments/runs/LinODEnet/ETTh12021-09-29T02:57:42/events.out.tfevents.1632877062.workstation.373922.0\",\n",
    "    size_guidance={  # see below regarding this argument\n",
    "        event_accumulator.COMPRESSED_HISTOGRAMS: 500,\n",
    "        event_accumulator.IMAGES: 4,\n",
    "        event_accumulator.AUDIO: 4,\n",
    "        event_accumulator.SCALARS: 0,\n",
    "        event_accumulator.HISTOGRAMS: 1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51336fb-3a59-44d4-bb27-c6b10a801d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ea.Reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ae4d0-667a-4708-b5a5-76051f19e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(ea.Scalars(\"train:metrics/MSE\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
