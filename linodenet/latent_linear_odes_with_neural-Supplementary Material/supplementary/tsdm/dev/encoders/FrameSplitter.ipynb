{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4, floatmode=\"fixed\", suppress=True)\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict, namedtuple\n",
    "from collections.abc import Callable, Collection, Hashable, Iterable, Mapping, Sequence\n",
    "from functools import singledispatchmethod\n",
    "from typing import Any, Final, Generic, Literal, Optional, Union, overload\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import torch\n",
    "from pandas import (\n",
    "    NA,\n",
    "    DataFrame,\n",
    "    DatetimeIndex,\n",
    "    Index,\n",
    "    MultiIndex,\n",
    "    Series,\n",
    "    Timedelta,\n",
    "    Timestamp,\n",
    ")\n",
    "from pandas.core.indexes.frozen import FrozenList\n",
    "from torch import Tensor\n",
    "\n",
    "from tsdm.datasets import KIWI_RUNS, TimeTensor\n",
    "from tsdm.encoders import *\n",
    "from tsdm.encoders import BaseEncoder\n",
    "from tsdm.tasks import KIWI_FINAL_PRODUCT\n",
    "from tsdm.utils.types import PathType\n",
    "from tsdm.utils.types.abc import HashableType\n",
    "\n",
    "np.set_printoptions(precision=4, floatmode=\"fixed\", suppress=True)\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = KIWI_RUNS()\n",
    "ts = ds.timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = KIWI_FINAL_PRODUCT()\n",
    "ts = task.timeseries.sort_index(axis=\"index\").sort_index(axis=\"columns\")\n",
    "channel_freq = pd.notna(ts).mean().sort_values()\n",
    "fast_channels = FrozenList(channel_freq[channel_freq >= 0.1].index)\n",
    "slow_channels = FrozenList(channel_freq[channel_freq < 0.1].index)\n",
    "FAST = ts[fast_channels].dropna(how=\"all\")\n",
    "SLOW = ts[slow_channels].dropna(how=\"all\")\n",
    "groups = {\"fast\": fast_channels, \"slow\": slow_channels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameSplitter(BaseEncoder, Mapping):\n",
    "    r\"\"\"Split a DataFrame into multiple groups.\n",
    "\n",
    "    The special value ``...`` (:class:`Ellipsis`) can be used to indicate\n",
    "    that all other columns belong to this group.\n",
    "\n",
    "    This function can be used on index columns as well.\n",
    "    \"\"\"\n",
    "\n",
    "    column_columns: Index\n",
    "    column_dtypes: Series\n",
    "    column_indices: list[int]\n",
    "\n",
    "    index_columns: Index\n",
    "    index_dtypes = Series\n",
    "    index_indices: list[int]\n",
    "\n",
    "    # FIXME: Union[types.EllipsisType, set[Hashable]] in 3.10\n",
    "    groups: dict[Hashable, Union[Hashable, list[Hashable]]]\n",
    "    group_indices: dict[Hashable, list[int]]\n",
    "\n",
    "    indices: dict[Hashable, list[int]]\n",
    "    has_ellipsis: bool = False\n",
    "    ellipsis: Optional[Hashable] = None\n",
    "\n",
    "    permutation: list[int]\n",
    "    inverse_permutation: list[int]\n",
    "\n",
    "    # @property\n",
    "    # def names(self) -> set[Hashable]:\n",
    "    #     r\"\"\"Return the union of all groups.\"\"\"\n",
    "    #     sets: list[set] = [\n",
    "    #         set(obj) if isinstance(obj, Iterable) else {Ellipsis}\n",
    "    #         for obj in self.groups.values()\n",
    "    #     ]\n",
    "    #     union: set[Hashable] = set.union(*sets)\n",
    "    #     assert sum(len(u) for u in sets) == len(union), \"Duplicate columns!\"\n",
    "    #     return union\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        groups: Iterable[Hashable],\n",
    "        /,\n",
    "        keep_index: bool = True,\n",
    "        dropna: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not isinstance(groups, Mapping):\n",
    "            groups = dict(enumerate(groups))\n",
    "\n",
    "        self.groups = {}\n",
    "        for key, obj in groups.items():\n",
    "            if obj is Ellipsis:\n",
    "                self.groups[key] = obj\n",
    "                self.ellipsis = key\n",
    "                self.has_ellipsis = True\n",
    "            elif isinstance(obj, str) or not isinstance(obj, Iterable):\n",
    "                self.groups[key] = [obj]\n",
    "            else:\n",
    "                self.groups[key] = list(obj)\n",
    "\n",
    "        self.keep_index = keep_index\n",
    "        self.dropna = dropna\n",
    "\n",
    "    def __repr__(self):\n",
    "        r\"\"\"Return a string representation of the object.\"\"\"\n",
    "        return repr_mapping(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        r\"\"\"Return the number of groups.\"\"\"\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __iter__(self):\n",
    "        r\"\"\"Iterate over the groups.\"\"\"\n",
    "        return iter(self.groups)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        r\"\"\"Return the group.\"\"\"\n",
    "        return self.groups[item]\n",
    "\n",
    "    def fit(self, original: DataFrame, /) -> None:\n",
    "        r\"\"\"Fit the encoder.\"\"\"\n",
    "        columns = DataFrame(original).copy()\n",
    "        index = columns.index.to_frame()\n",
    "\n",
    "        self.column_dtypes = original.dtypes\n",
    "        self.column_columns = original.columns\n",
    "        self.index_columns = index.columns\n",
    "        self.index_dtypes = index.dtypes\n",
    "\n",
    "        assert not (\n",
    "            j := set(self.index_columns) & set(self.column_columns)\n",
    "        ), f\"index columns and data columns must be disjoint {j}!\"\n",
    "\n",
    "        data = pd.concat([index, columns], axis=\"columns\")\n",
    "\n",
    "        if not self.keep_index:\n",
    "            data = data.reset_index(drop=True)\n",
    "\n",
    "        def get_idx(cols: Any) -> list[int]:\n",
    "            return [data.columns.get_loc(i) for i in cols]\n",
    "\n",
    "        self.indices: dict[Hashable, int] = dict(enumerate(data.columns))\n",
    "        self.group_indices: dict[Hashable, list[int]] = {}\n",
    "        self.column_indices = get_idx(self.column_columns)\n",
    "        self.index_indices = get_idx(self.index_columns)\n",
    "\n",
    "        # replace ellipsis indices\n",
    "        if self.has_ellipsis:\n",
    "            # FIXME EllipsisType in 3.10\n",
    "            fixed_cols = set().union(\n",
    "                *(\n",
    "                    set(cols)  # type: ignore[arg-type]\n",
    "                    for cols in self.groups.values()\n",
    "                    if cols is not Ellipsis\n",
    "                )\n",
    "            )\n",
    "            ellipsis_columns = [c for c in data.columns if c not in fixed_cols]\n",
    "            self.groups[self.ellipsis] = ellipsis_columns\n",
    "\n",
    "        # set column indices\n",
    "        self.permutation = []\n",
    "        for group, columns in self.groups.items():\n",
    "            if columns is Ellipsis:\n",
    "                continue\n",
    "            self.group_indices[group] = get_idx(columns)\n",
    "            self.permutation += self.group_indices[group]\n",
    "        self.inverse_permutation = np.argsort(self.permutation).tolist()\n",
    "        # sorted(p.copy(), key=p.__getitem__)\n",
    "\n",
    "    def encode(self, original: DataFrame, /) -> tuple[DataFrame, ...]:\n",
    "        r\"\"\"Encode the data.\"\"\"\n",
    "        # copy the frame and add index as columns.\n",
    "        columns = DataFrame(original).copy()\n",
    "        index = columns.index.to_frame()\n",
    "        data = pd.concat([index, columns], axis=\"columns\")\n",
    "\n",
    "        if not self.keep_index:\n",
    "            data = data.reset_index(drop=True)\n",
    "\n",
    "        data_columns = set(data.columns)\n",
    "\n",
    "        assert data_columns <= set(self.indices.values()), (\n",
    "            f\"Unknown columns {data_columns - set(self.indices)}.\"\n",
    "            \"If you want to encode unknown columns add a group ``...`` (Ellipsis).\"\n",
    "        )\n",
    "\n",
    "        encoded = []\n",
    "        for columns in self.groups.values():\n",
    "            encoded.append(data[columns].squeeze(axis=\"columns\"))\n",
    "        return tuple(encoded)\n",
    "\n",
    "    def decode(self, data: tuple[DataFrame, ...], /) -> DataFrame:\n",
    "        r\"\"\"Decode the data.\"\"\"\n",
    "        data = tuple(DataFrame(x) for x in data)\n",
    "        joined = pd.concat(data, axis=\"columns\")\n",
    "\n",
    "        # unshuffle the columns, restoring original order\n",
    "        joined = joined.iloc[..., self.inverse_permutation]\n",
    "\n",
    "        # Assemble the columns\n",
    "        columns = joined.iloc[..., self.column_indices]\n",
    "        columns.columns = self.column_columns\n",
    "        columns = columns.astype(self.column_dtypes)\n",
    "        columns = columns.squeeze(axis=\"columns\")\n",
    "\n",
    "        # assemble the index\n",
    "        index = joined.iloc[..., self.index_indices]\n",
    "        index.columns = self.index_columns\n",
    "        index = index.astype(self.index_dtypes)\n",
    "        index = index.squeeze(axis=\"columns\")\n",
    "\n",
    "        if isinstance(index, Series):\n",
    "            decoded = columns.set_index(index)\n",
    "        else:\n",
    "            decoded = columns.set_index(MultiIndex.from_frame(index))\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from pandas.core.indexes.frozen import FrozenList\n",
    "\n",
    "\n",
    "def pairwise_disjoint(sets: Iterable[set]):\n",
    "    union = set().union(*sets)\n",
    "    return len(union) == sum(len(s) for s in sets)\n",
    "\n",
    "\n",
    "class FrameSplitter(BaseEncoder, Mapping):\n",
    "    r\"\"\"Split a DataFrame into multiple groups.\n",
    "\n",
    "    The special value ``...`` (:class:`Ellipsis`) can be used to indicate\n",
    "    that all other columns belong to this group.\n",
    "\n",
    "    This function can be used on index columns as well.\n",
    "\n",
    "    Index mapping\n",
    "\n",
    "    [0|1|2|3|4|5]\n",
    "\n",
    "    [2|0|1], [5|4]\n",
    "\n",
    "    corresponds to mapping\n",
    "\n",
    "    +---+---+---+---+---+---+\n",
    "    | 0 | 1 | 2 | 3 | 4 | 5 |\n",
    "    +===+===+===+===+===+===+\n",
    "    | 1 | 2 | 0 | - | 5 | 4 |\n",
    "    +---+---+---+---+---+---+\n",
    "\n",
    "\n",
    "    with inverse\n",
    "\n",
    "    +---+---+---+---+---+---+\n",
    "    | 0 | 1 | 2 | 3 | 4 | 5 |\n",
    "    +===+===+===+===+===+===+\n",
    "    | 1 | 2 | 0 | - | 5 | 4 |\n",
    "    +---+---+---+---+---+---+\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    column_columns: Index\n",
    "    column_dtypes: Series\n",
    "    column_indices: list[int]\n",
    "\n",
    "    index_columns: Index\n",
    "    index_dtypes = Series\n",
    "    index_indices: list[int]\n",
    "\n",
    "    # FIXME: Union[types.EllipsisType, set[Hashable]] in 3.10\n",
    "    groups: dict[Hashable, Union[Hashable, list[Hashable]]]\n",
    "    group_indices: dict[Hashable, list[int]]\n",
    "\n",
    "    indices: dict[Hashable, list[int]]\n",
    "    has_ellipsis: bool = False\n",
    "    ellipsis: Optional[list[Hashable]] = None\n",
    "\n",
    "    permutation: list[int]\n",
    "    inverse_permutation: list[int]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        groups: Union[Iterable[Hashable], Mapping[Hashable, Hashable]],\n",
    "        /,\n",
    "        dropna: bool = False,\n",
    "        fillna: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not isinstance(groups, Mapping):\n",
    "            groups = dict(enumerate(groups))\n",
    "\n",
    "        self.groups = {}\n",
    "        for key, obj in groups.items():\n",
    "            if obj is Ellipsis:\n",
    "                self.groups[key] = obj\n",
    "                self.ellipsis = key\n",
    "                self.has_ellipsis = True\n",
    "            elif isinstance(obj, str) or not isinstance(obj, Iterable):\n",
    "                self.groups[key] = FrozenList([obj])\n",
    "            else:\n",
    "                self.groups[key] = FrozenList(obj)\n",
    "\n",
    "        column_sets = [\n",
    "            set(cols) for cols in self.groups.values() if cols is not Ellipsis\n",
    "        ]\n",
    "        self.fixed_columns = set().union(*column_sets)\n",
    "        assert pairwise_disjoint(column_sets)\n",
    "\n",
    "        self.inverse_groups = {}\n",
    "        for group, columns in self.groups.items():\n",
    "            if columns is Ellipsis:\n",
    "                continue\n",
    "            for column in columns:\n",
    "                inverse_groups[column] = group\n",
    "\n",
    "        # self.keep_index = keep_index\n",
    "        self.dropna = dropna\n",
    "        self.fillna = fillna\n",
    "\n",
    "    def __repr__(self):\n",
    "        r\"\"\"Return a string representation of the object.\"\"\"\n",
    "        return repr_mapping(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        r\"\"\"Return the number of groups.\"\"\"\n",
    "        return len(self.groups)\n",
    "\n",
    "    def __iter__(self):\n",
    "        r\"\"\"Iterate over the groups.\"\"\"\n",
    "        return iter(self.groups)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        r\"\"\"Return the group.\"\"\"\n",
    "        return self.groups[item]\n",
    "\n",
    "    def fit(self, original: DataFrame, /) -> None:\n",
    "        r\"\"\"Fit the encoder.\"\"\"\n",
    "        data = DataFrame(original).copy()\n",
    "\n",
    "        if self.dropna and not df.index.is_monotonic_increasing:\n",
    "            raise ValueError(f\"If {self.dropna=}, Index must be monotonic increasing!\")\n",
    "        self.original_dtypes = original.dtypes\n",
    "        self.original_columns = original.columns\n",
    "\n",
    "        self.variable_indices = {col: [] for col in self.original_columns}\n",
    "        for group, columns in self.groups.items():\n",
    "            if columns is Ellipsis:\n",
    "                continue\n",
    "            for column in columns:\n",
    "                self.variable_indices[column].append(group)\n",
    "\n",
    "        if self.has_ellipsis:\n",
    "            self.ellipsis_columns = [\n",
    "                c for c in data.columns if c not in self.fixed_columns\n",
    "            ]\n",
    "        else:\n",
    "            unused_columns = (\n",
    "                set() if self.has_ellipsis else set(data.columns) - self.fixed_columns\n",
    "            )\n",
    "            data = data.drop(columns=unused_columns)\n",
    "\n",
    "        columns_index = data.columns.to_series().reset_index(drop=True)\n",
    "        reverse_index = Series(columns_index.index, index=columns_index)\n",
    "\n",
    "        self.indices: dict[Hashable, int] = dict(enumerate(data.columns))\n",
    "        self.group_indices: dict[Hashable, list[int]] = {}\n",
    "\n",
    "        # set column indices\n",
    "        self.permutation = []\n",
    "        for group, columns in self.groups.items():\n",
    "            if columns is Ellipsis:\n",
    "                self.group_indices[group] = reverse_index[\n",
    "                    self.ellipsis_columns\n",
    "                ].to_list()\n",
    "            else:\n",
    "                self.group_indices[group] = reverse_index[columns].to_list()\n",
    "            self.permutation += self.group_indices[group]\n",
    "\n",
    "        # compute inverse permutation\n",
    "        self.inverse_permutation = np.argsort(self.permutation).tolist()\n",
    "        # sorted(p.copy(), key=p.__getitem__)\n",
    "\n",
    "    def encode(self, original: DataFrame, /) -> tuple[DataFrame, ...]:\n",
    "        r\"\"\"Encode the data.\"\"\"\n",
    "        # copy the frame and add index as columns.\n",
    "        data = DataFrame(original).copy()\n",
    "        # index = columns.index.to_frame()\n",
    "        # data = pd.concat([index, columns], axis=\"columns\")\n",
    "\n",
    "        # if not self.keep_index:\n",
    "        #     data = data.reset_index(drop=True)\n",
    "\n",
    "        if not self.has_ellipsis and set(data.columns) > self.fixed_columns:\n",
    "            warnings.warn(\n",
    "                f\"Unknown columns {set(data.columns) - self.fixed_columns}.\"\n",
    "                \"If you want to encode unknown columns add a group ``...`` (Ellipsis).\"\n",
    "            )\n",
    "\n",
    "        encoded_frames = []\n",
    "        for columns in self.groups.values():\n",
    "            if columns is Ellipsis:\n",
    "                encoded = data[self.ellipsis_columns]\n",
    "            else:\n",
    "                encoded = data[columns]\n",
    "            if self.dropna:\n",
    "                encoded = encoded.dropna(axis=\"index\", how=\"all\")\n",
    "            encoded_frames.append(encoded)\n",
    "\n",
    "        return tuple(encoded_frames)\n",
    "\n",
    "    def decode(self, data: tuple[DataFrame, ...], /) -> DataFrame:\n",
    "        r\"\"\"Decode the data.\"\"\"\n",
    "        data = tuple(DataFrame(x) for x in data)\n",
    "        joined = pd.concat(data, axis=\"columns\")\n",
    "\n",
    "        # bring columns in order\n",
    "        joined = joined.iloc[..., self.inverse_permutation]\n",
    "        reconstructed = DataFrame(columns=self.original_columns)\n",
    "        reconstructed[joined.columns] = joined\n",
    "        reconstructed = reconstructed.astype(self.original_dtypes)\n",
    "\n",
    "        if self.dropna:\n",
    "            reconstructed = reconstructed.sort_index()\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = ts.iloc[:200]\n",
    "\n",
    "encoder = FrameSplitter(\n",
    "    [slow_channels, fast_channels],\n",
    "    dropna=True\n",
    "    # {\"D\" : [\"run_id\",\"measurement_time\"], \"A\": \"Flow_Air\", \"B\": [\"StirringSpeed\", \"Temperature\"], \"C\": Ellipsis}\n",
    ")\n",
    "encoder.fit(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoder.encode(T)\n",
    "encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = encoder.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.testing.assert_frame_equal(T, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class A:\n",
    "    \n",
    "    @abstractmethod\n",
    "    def f(self, ...):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.testing.assert_frame_equal(T, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
