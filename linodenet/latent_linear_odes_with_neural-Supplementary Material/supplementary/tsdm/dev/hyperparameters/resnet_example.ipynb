{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "import os\n",
    "from collections.abc import Callable\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from functools import update_wrapper, wraps\n",
    "from inspect import Parameter, signature\n",
    "from time import perf_counter_ns\n",
    "from types import MethodType\n",
    "from typing import Any, Final, Optional, Union, overload, TypedDict\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4, floatmode=\"fixed\", suppress=True)\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import OrderedDict\n",
    "from typing import Any, TypeVar\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, jit, nn\n",
    "\n",
    "# from tsdm.models.generic.dense import ReverseDense\n",
    "# from tsdm.utils import deep_dict_update, initialize_from_config\n",
    "# from tsdm.utils.decorators import trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import pydantic\n",
    "from pydantic import BaseModel\n",
    "from pydantic import dataclasses as pydantic_dataclasses\n",
    "from pydantic.dataclasses import dataclass as pydantic_dataclass\n",
    "\n",
    "# from dataclasses import KW_ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    input_size: int\n",
    "    output_size: int\n",
    "    latent_size: Optional[int] = None\n",
    "    num_layers: int = 2\n",
    "    activation: str = \"relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataclasses.asdict(Config(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydantic_dataclass\n",
    "class Config:\n",
    "    input_size: int\n",
    "    output_size: int\n",
    "    latent_size: Optional[int] = None\n",
    "    num_layers: int = 2\n",
    "    activation: str = \"relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataclasses.asdict(Config(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla DataClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Sequential):\n",
    "    HP: Dict[str, Any]\n",
    "\n",
    "    @dataclass\n",
    "    class Config:\n",
    "        input_size: int\n",
    "        output_size: int\n",
    "        latent_size: Optional[int] = None\n",
    "        num_layers: int = 2\n",
    "        activation: str = \"relu\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        config = self.Config(*args, **kwargs)\n",
    "\n",
    "        if config.latent_size is None:\n",
    "            config.latent_size = (config.input_size + config.output_size) // 2\n",
    "\n",
    "        self.HP = dataclasses.asdict(config)\n",
    "\n",
    "        layers = [nn.Linear(config.input_size, config.latent_size)]\n",
    "\n",
    "        for _ in range(config.num_layers):\n",
    "            layers.append(nn.Linear(config.latent_size, config.latent_size))\n",
    "\n",
    "        layers.append(nn.Linear(config.latent_size, config.output_size))\n",
    "\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(2, 3)\n",
    "x = torch.randn(7, 2)\n",
    "model(x)\n",
    "scripted = jit.script(model)\n",
    "scripted(x)\n",
    "jit.save(scripted, \"model\")\n",
    "model = jit.load(\"model\")\n",
    "model.HP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic DataClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Sequential):\n",
    "    HP: Dict[str, Any]\n",
    "\n",
    "    @pydantic_dataclass\n",
    "    class Config:\n",
    "        input_size: int\n",
    "        output_size: int\n",
    "        latent_size: Optional[int] = None\n",
    "        num_layers: int = 2\n",
    "        activation: str = \"relu\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        config = self.Config(*args, **kwargs)\n",
    "\n",
    "        if config.latent_size is None:\n",
    "            config.latent_size = (config.input_size + config.output_size) // 2\n",
    "\n",
    "        self.HP = dataclasses.asdict(config)\n",
    "\n",
    "        layers = [nn.Linear(config.input_size, config.latent_size)]\n",
    "\n",
    "        for _ in range(config.num_layers):\n",
    "            layers.append(nn.Linear(config.latent_size, config.latent_size))\n",
    "\n",
    "        layers.append(nn.Linear(config.latent_size, config.output_size))\n",
    "\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(2, 3)\n",
    "x = torch.randn(7, 2)\n",
    "model(x)\n",
    "scripted = jit.script(model)\n",
    "scripted(x)\n",
    "jit.save(scripted, \"model\")\n",
    "model = jit.load(\"model\")\n",
    "model.HP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Sequential):\n",
    "    HP: Dict[str, Any]\n",
    "\n",
    "    class Config(BaseModel):\n",
    "        input_size: int\n",
    "        output_size: int\n",
    "        latent_size: Optional[int] = None\n",
    "        num_layers: int = 2\n",
    "        activation: str = \"relu\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        config = self.Config(*args, **kwargs)\n",
    "\n",
    "        if config.latent_size is None:\n",
    "            config.latent_size = (config.input_size + config.output_size) // 2\n",
    "\n",
    "        self.HP = dataclasses.asdict(config)\n",
    "\n",
    "        layers = [nn.Linear(config.input_size, config.latent_size)]\n",
    "\n",
    "        for _ in range(config.num_layers):\n",
    "            layers.append(nn.Linear(config.latent_size, config.latent_size))\n",
    "\n",
    "        layers.append(nn.Linear(config.latent_size, config.output_size))\n",
    "\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataclasses.MISSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    input_size: int\n",
    "    output_size: int\n",
    "    latent_size: int\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.latent_size is Any:\n",
    "            self.latent_size = self.input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    input_size: int\n",
    "    output_size: int\n",
    "    latent_size: int = Any\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.latent_size is Any:\n",
    "            self.latent_size = self.input_size\n",
    "\n",
    "\n",
    "conf = Config(2, 3, latent_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deepset(nn.Sequential):\n",
    "    HP: Dict[str, Any]\n",
    "\n",
    "    @dataclass\n",
    "    class Config:\n",
    "        input_size: int\n",
    "        output_size: int\n",
    "        latent_size: Optional[int] = None\n",
    "        encoder:\n",
    "        decoder:\n",
    "        \n",
    "    \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        config = self.Config(*args, **kwargs)\n",
    "        \n",
    "        if config.latent_size is None:\n",
    "            config.latent_size = (config.input_size + config.output_size) // 2\n",
    "\n",
    "        self.HP = dataclasses.asdict(config)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
