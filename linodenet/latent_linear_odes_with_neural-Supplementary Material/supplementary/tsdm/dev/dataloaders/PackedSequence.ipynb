{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac269a48-80dd-424b-8dd1-2cfd8458c2df",
   "metadata": {},
   "source": [
    "# Efficient TS batching via PackedSequence\n",
    "\n",
    "\n",
    "- <https://discuss.pytorch.org/t/customized-rnn-cell-which-can-accept-packsequence/1067>\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52413ecc-e549-45ba-b25e-d5cc42636371",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc58cb4-80cc-446d-a30c-e5a8ab89041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import (\n",
    "    pack_sequence,\n",
    "    pad_sequence,\n",
    "    pack_padded_sequence,\n",
    "    pad_packed_sequence,\n",
    "    PackedSequence,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d506398-ba70-4e21-b1fd-8db4419a75ca",
   "metadata": {},
   "source": [
    "#### Classes:\n",
    "\n",
    "- [PackedSequence](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence)\n",
    "\n",
    "#### Functions:\n",
    "\n",
    "- [pack_padded_sequence](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence): \n",
    "    - inputs: `tuple[inputs: Tensor, lengths: Tensor]`\n",
    "    - output: `PackedSequence[data: Tensor, batch_sizes: Tensor]`\n",
    "    - signature: `[BS, max[LEN], *DIMS], [BS] -> [sum(LEN), *DIMS], [max[LEN]]`\n",
    "\n",
    "- [pad_packed_sequence](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html#torch.nn.utils.rnn.pad_packed_sequence): \n",
    "    - inputs: `PackedSequence[data: Tensor, batch_sizes: Tensor]`\n",
    "    - output: `tuple[inputs: Tensor, lengths: Tensor]`\n",
    "    - signature: `[sum(LEN), *DIMS], [max[LEN]] -> [BS, max[LEN], *DIMS], [BS]`\n",
    "\n",
    "- [pad_sequence](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html#torch.nn.utils.rnn.pad_sequence): \n",
    "    - inputs: `list[Tensor]`\n",
    "    - output: `Tensor`\n",
    "    - signature: `BS×[LEN[k], *DIMS] -> [BS, max[LEN], *DIMS]`\n",
    "\n",
    "- [pack_sequence](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html#torch.nn.utils.rnn.pack_sequence): \n",
    "    - inputs: `list[Tensor]`\n",
    "    - output: `PackedSequence[data: Tensor, batch_sizes: Tensor]`\n",
    "    - signature `BS×[SEQ_LEN[k], *DIMS] -> [sum(LEN), *DIMS], [max[SEQ_LEN]]`\n",
    "\n",
    "#### TODO:\n",
    "\n",
    "- unpad_sequence: tuple[Tensor, Tensor] -> list[Tensor]\n",
    "\n",
    "- unpack_sequnce: PackedSequence -> list[Tensor]\n",
    "\n",
    "#### Questions: \n",
    "\n",
    "- How to apply loss functions directly on packed / padded Tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0290c699-477f-42d9-8431-0f17a71b592f",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "PackedSequence stores data in a peculiar way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28ff07-4b7d-467d-8c68-4c5249e2115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation\n",
    "batch_size = 4\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "seq_len_range = (2, 9)\n",
    "num_batches = 10\n",
    "low, high = 0, 9\n",
    "\n",
    "rnn = nn.RNN(input_size, hidden_size, num_layers=4, bias=True, batch_first=True)\n",
    "rnn.to(device)\n",
    "rnn.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed099c0-d068-4c56-a19a-6c261f56d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "batches = list()\n",
    "for idx in range(num_batches):\n",
    "    batch = []\n",
    "    for k in range(batch_size):\n",
    "        rand_len = np.random.randint(*seq_len_range)\n",
    "        x = torch.randint(low, high, (rand_len, input_size), device=device)\n",
    "        y = torch.randint(low, high, (rand_len, hidden_size), device=device)\n",
    "        batch += [(x, y)]\n",
    "    batch = sorted(batch, key=lambda x: x[0].size(0), reverse=True)\n",
    "    batches += [batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77d312-997b-4de0-9912-6aca77f3997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batches[0]\n",
    "[[tensor.shape for tensor in x] for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4decf25-0c71-4ffc-b6c7-ce886183e94f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = [x[0] for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25a821-a00d-4b2d-bdbe-80b9d4416bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Size([222, 3])\n",
    "# [LEN, 3]\n",
    "packed = pack_sequence(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdde67-e25b-4e84-8ebf-dd9331b21c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_packed_sequence(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af16f9-97e6-4e05-95da-f9e6c1c188fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f336092-1767-4c3f-965c-fad5ccde7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "[batch.shape for batch in batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60c3df-17e6-4316-a1ab-422e9591a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(sequence: list[torch.Tensor], **kwargs) -> tuple[PackedSequence, list[int]]:\n",
    "    lengths = list(map(len, sequence))\n",
    "    tensors = [tensor for length, tensor in zip(lengths, sequence) if length > 0]\n",
    "    packed_sequence = pack_sequence(tensors, **kwargs)\n",
    "    return packed_sequence, lengths\n",
    "\n",
    "\n",
    "def unpack(packed_sequence: PackedSequence, lengths: list[int]) -> list[torch.Tensor]:\n",
    "    device = packed_sequence.data.device\n",
    "    dtype = packed_sequence.data.dtype\n",
    "    trailing_dims = packed_sequence.data.shape[1:]\n",
    "    unpacked_sequence = []\n",
    "    idx_map = {}\n",
    "    head = 0\n",
    "    for b_idx, length in enumerate(lengths):\n",
    "        unpacked_sequence.append(\n",
    "            torch.zeros(length, *trailing_dims, device=device, dtype=dtype)\n",
    "        )\n",
    "        if length > 0:\n",
    "            idx_map[head] = b_idx\n",
    "            head += 1\n",
    "    head = 0\n",
    "    for l_idx, b_size in enumerate(packed_sequence.batch_sizes):\n",
    "        for b_idx in range(b_size):\n",
    "            unpacked_sequence[idx_map[b_idx]][l_idx] = packed_sequence.data[head]\n",
    "            head += 1\n",
    "    return unpacked_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6971884-2ea8-484c-9a71-f1ccc16011ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "batches = list()\n",
    "for idx in range(num_batches):\n",
    "    batch = []\n",
    "    for k in range(batch_size):\n",
    "        rand_len = np.random.randint(*seq_len_range)\n",
    "        x = torch.rand((rand_len, input_size), device=device)\n",
    "        y = torch.rand((rand_len, hidden_size), device=device)\n",
    "        batch += [(x, y)]\n",
    "    # batch = sorted(batch, key=lambda x: x[0].size(0), reverse=True)\n",
    "    batches += [batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed3d816-a993-4125-bd43-5fe74147a5b7",
   "metadata": {},
   "source": [
    "## Python loops = too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43575b-b819-4c5f-a63a-883e7720b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for padded input\n",
    "start = time.time()\n",
    "for batch in batches:\n",
    "    yhat = []\n",
    "    l = torch.tensor(0, dtype=dtype, device=device)\n",
    "    for x, y in batch:\n",
    "        yhat = rnn(x.unsqueeze(0))[0].squeeze(dim=0)\n",
    "        r = (y - yhat) ** 2\n",
    "        l += torch.sum(r)\n",
    "    l.backward()\n",
    "    g = torch.cat([w.grad.flatten() for w in rnn.parameters()])\n",
    "    rnn.zero_grad()\n",
    "end = time.time()\n",
    "print(f\"elapsed time for padded input: {end - start} secs\")\n",
    "print(torch.sum(torch.isnan(g)))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d22ee-de40-4cea-b3c0-1f53ec46b1d2",
   "metadata": {},
   "source": [
    "## Padded is much faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0998cec6-6524-4295-8b9a-f06c8614b750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for padded input\n",
    "start = time.time()\n",
    "for batch in batches:\n",
    "    x, y = zip(*batch)\n",
    "    x = pad_sequence(x, padding_value=np.nan, batch_first=True)\n",
    "    y = pad_sequence(y, padding_value=np.nan, batch_first=True)\n",
    "    yhat = rnn(x)[0]\n",
    "    mask = torch.isnan(yhat)\n",
    "    zero = torch.tensor(0, dtype=dtype, device=device)\n",
    "    r = torch.where(mask, zero, (y - yhat) ** 2)\n",
    "    l = torch.sum(r)\n",
    "    l.backward()\n",
    "    g = torch.cat([w.grad.flatten() for w in rnn.parameters()])\n",
    "    rnn.zero_grad()\n",
    "end = time.time()\n",
    "print(f\"elapsed time for padded input: {end - start} secs\")\n",
    "print(torch.sum(torch.isnan(g)))\n",
    "print(r.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e565ed6-7c0a-470c-84b0-f67e5aaba12f",
   "metadata": {},
   "source": [
    "## Packed is also fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a0db5-ae1b-4bed-8b93-cb774aa70f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for packed input\n",
    "start = time.time()\n",
    "for batch in batches:\n",
    "    x, y = zip(*batch)\n",
    "    x = pack_sequence(x)\n",
    "    y = pack_sequence(y)\n",
    "    yhat = rnn(x)[0]\n",
    "    r = (y.data - yhat.data) ** 2\n",
    "    l = torch.sum(r)\n",
    "    l.backward()\n",
    "    g = torch.cat([w.grad.flatten() for w in rnn.parameters()])\n",
    "    rnn.zero_grad()\n",
    "end = time.time()\n",
    "print(f\"elapsed time for packed input: {end - start} secs\")\n",
    "print(torch.sum(torch.isnan(g)))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546727f4-4ead-4520-9cb2-49ea696c2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for packed input with unpack\n",
    "start = time.time()\n",
    "for batch in batches:\n",
    "    x_batch, y_batch = zip(*batch)\n",
    "    x_packed, _ = pack(x_batch)\n",
    "    y_packed, lengths = pack(y_batch)\n",
    "    yhat_packed = rnn(x_packed)[0]\n",
    "\n",
    "    r = torch.tensor(0, dtype=dtype, device=device)\n",
    "    for y, yhat in zip(y_batch, unpack(y_packed, lengths)):\n",
    "        r += torch.mean((y - yhat) ** 2)\n",
    "    r.backward()\n",
    "    g = torch.cat([w.grad.flatten() for w in rnn.parameters()])\n",
    "    print(torch.sum(torch.isnan(g)))\n",
    "    rnn.zero_grad()\n",
    "end = time.time()\n",
    "print(f\"elapsed time for packed input: {end - start} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b8e62-8f32-4280-bbb4-81986c6909de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device(\"cpu\")\n",
    "rnn = nn.RNN(2, 2, num_layers=4, bias=True, batch_first=True)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffe958-d2a0-4553-97e8-01842ecc91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(np.random.randint(0, 9, (5, 2)), dtype=dtype, device=device)\n",
    "b = torch.tensor(np.random.randint(0, 9, (4, 2)), dtype=dtype, device=device)\n",
    "c = torch.tensor(np.random.randint(0, 9, (3, 2)), dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603d97f-07b2-4882-a907-303ec4bd73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [a, b, c]\n",
    "lengths = [len(x) for x in batch]\n",
    "x, lengths = pack([a, b, c])\n",
    "rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b837b1-ffb8-4909-9c7d-8123845203c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rnn(x)[0]\n",
    "y = unpack(y, lengths)\n",
    "yhat = [rnn(z.unsqueeze(dim=0))[0] for z in batch]\n",
    "[z - zhat for z, zhat in zip(y, yhat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06575167-4fef-4e5a-bf3f-102b5210d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = pad_sequence(batch, padding_value=np.nan, batch_first=True)\n",
    "rnn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53d94c-07e0-49fc-b023-09d70b138ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c4f89f-f961-49d5-9e8a-aebbfa0afc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
