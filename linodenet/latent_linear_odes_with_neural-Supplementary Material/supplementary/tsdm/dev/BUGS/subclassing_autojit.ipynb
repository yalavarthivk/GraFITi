{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "import logging\n",
    "import os\n",
    "from collections.abc import Callable\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from functools import wraps, update_wrapper\n",
    "from inspect import Parameter, signature\n",
    "from time import perf_counter_ns\n",
    "from types import MethodType\n",
    "from typing import Any, Optional, Union, overload\n",
    "\n",
    "np.set_printoptions(precision=4, floatmode=\"fixed\", suppress=True)\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import OrderedDict\n",
    "from typing import Any, TypeVar\n",
    "import torch\n",
    "from torch import Tensor, jit, nn\n",
    "\n",
    "from tsdm.models.generic.dense import ReverseDense\n",
    "from tsdm.utils import deep_dict_update, initialize_from_config\n",
    "from tsdm.utils.decorators import trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnModuleType = TypeVar(\"nnModuleType\", bound=nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(f\"AutoJIT@{cls.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\displaystyle \\|A\\|_{p,q}=\\left(\\frac{1}{n}\\sum _{j=1}^{n}\\left(\\frac{1}{m}\\sum _{i=1}^{m}|a_{ij}|^{p}\\right)^{\\frac {q}{p}}\\right)^{\\frac {1}{q}}.}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autojit(\n",
    "    base_class: type[nnModuleType], /, *, inherit: bool = False\n",
    ") -> type[nnModuleType]:\n",
    "    assert issubclass(base_class, nn.Module)\n",
    "\n",
    "    @wraps(base_class, updated=())\n",
    "    class WrappedClass(base_class):  # type: ignore  # pylint: disable=too-few-public-methods\n",
    "        r\"\"\"A simple Wrapper.\"\"\"\n",
    "\n",
    "        @trace\n",
    "        def __new__(cls, *args: Any, **kwargs: Any) -> nnModuleType:  # type: ignore[misc]\n",
    "            print(f\"{cls=}, {args=}, {kwargs=}\")\n",
    "            instance: nnModuleType = super().__new__(cls)\n",
    "            instance.__init__(*args, **kwargs)\n",
    "            scripted: nnModuleType = jit.script(instance)\n",
    "            # If __new__() does not return an instance of cls, then the new instanceâ€™s __init__() method will not be invoked!\n",
    "            return scripted\n",
    "\n",
    "    assert issubclass(WrappedClass, base_class)\n",
    "    return WrappedClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autojit\n",
    "class Series(nn.ModuleList):\n",
    "    \"\"\"A ResNet model.\"\"\"\n",
    "\n",
    "    @trace\n",
    "    def __init__(self, *modules: nn.Module) -> None:\n",
    "        print(\"__INIT__ CALLED\")\n",
    "        super().__init__(modules)\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        r\"\"\"Forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "        \"\"\"\n",
    "        for block in self:\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# @autojit\n",
    "class ResNet(Series):\n",
    "    @trace\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    @jit.export\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        r\"\"\"Forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "        \"\"\"\n",
    "        for block in self:\n",
    "            x = x + block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [\n",
    "    nn.Linear(4, 4),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4, 4),\n",
    "]\n",
    "x = torch.randn(7, 4)\n",
    "model = Series(*blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)\n",
    "torch.linalg.norm(y).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(*blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)\n",
    "torch.linalg.norm(y).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    @trace\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        return super().__new__(cls, *args, **kwargs)\n",
    "\n",
    "    @trace\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "class B:\n",
    "    @trace\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        return super().__new__(cls, *args, **kwargs)\n",
    "\n",
    "    @trace\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "obj = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
