{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad4886-bf56-4f02-83f8-e949b5a12e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644fc9a2-7b35-483d-860e-d1e77185c197",
   "metadata": {},
   "source": [
    "# Traffic Dataset\n",
    "\n",
    "There are two files for each fold, the data file and the labels file. We have split the 440 time series between train and test folds, but you are of course free to merge them to consider a different cross validation setting.\n",
    "- The PEMS_train textfile has 263 lines. Each line describes a time-series provided as a matrix. The matrix syntax is that of Matlab, e.g. [ a b ; c d] is the matrix with row vectors [a b] and [c d] in that order. Each matrix describes the different occupancies rates (963 lines, one for each station/detector) sampled every 10 minutes during the day (144 columns).\n",
    "- The PEMS_trainlabel text describes, for each day of measurements described above, the day of the week on which the data was sampled, namely an integer between 1 (Mon.) and 7 (Sun.).\n",
    "\n",
    "- PEMS_test and PEMS_testlabels are formatted in the same way, except that there are 173 test instances.\n",
    "\n",
    "- The permutation that I used to shuffle the dataset is given in the randperm file. If you need to rearrange the data so that it follows the calendar order, you should merge train and test samples and reorder them using the inverse permutation of randperm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e22b6e-7e7c-436a-8b70-828745d0ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.datasets import BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7461896b-b634-4d84-822b-3ebcb19580f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Traffic(BaseDataset):\n",
    "    url: str = r\"https://archive.ics.uci.edu/ml/machine-learning-databases/00204/\"\n",
    "    info_url: str = r\"https://archive.ics.uci.edu/ml/datasets/PEMS-SF\"\n",
    "\n",
    "\n",
    "Traffic.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5010c-bb8b-482a-9a9b-9f95cea0c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "from pandas import DataFrame, read_csv, read_hdf, Series\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e192fa84-0fd6-499c-a7fc-8ed6bb73b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_true = True\n",
    "\n",
    "# The true anomalies were found by iteratively adding them 1 by one,\n",
    "# Each time checking when the first date was when\n",
    "# labels[invperm].map(weekdays) didn't match with dates.day_name()\n",
    "true_dates = pandas.date_range(\"2008-01-01\", \"2009-03-26\", freq=\"d\", name=\"day\")\n",
    "true_anomalies = pandas.DatetimeIndex(\n",
    "    {\n",
    "        \"2008-01-01\": \"New Year’s Day\",\n",
    "        \"2008-01-21\": \"Martin Luther King Jr. Day\",\n",
    "        \"2008-02-18\": \"Washington’s Birthday\",\n",
    "        \"2008-03-09\": \"anomaly + wrong year\",\n",
    "        \"2008-05-26\": \"Memorial Day\",\n",
    "        \"2008-07-04\": \"Independence Day\",\n",
    "        \"2008-09-01\": \"Labor Day\",\n",
    "        \"2008-10-20\": \"???\",\n",
    "        \"2008-11-17\": \"???\",\n",
    "        \"2008-12-07\": \"???\",\n",
    "        \"2009-02-23\": \"???\",\n",
    "    }\n",
    ")\n",
    "true_weekdays = {\n",
    "    \"1\": \"Sunday\",\n",
    "    \"2\": \"Monday\",\n",
    "    \"3\": \"Tuesday\",\n",
    "    \"4\": \"Wednesday\",\n",
    "    \"5\": \"Thursday\",\n",
    "    \"6\": \"Friday\",\n",
    "    \"7\": \"Saturday\",\n",
    "}\n",
    "\n",
    "\n",
    "false_dates = pandas.date_range(\"2008-01-01\", \"2009-03-30\", freq=\"d\", name=\"day\")\n",
    "false_anomalies = pandas.DatetimeIndex(\n",
    "    {\n",
    "        \"Jan. 1, 2008\": \"New Year’s Day\",\n",
    "        \"Jan. 21, 2008\": \"Martin Luther King Jr. Day\",\n",
    "        \"Feb. 18, 2008\": \"Washington’s Birthday\",\n",
    "        \"Mar. 9, 2008\": \"Anomaly day\",\n",
    "        \"May 26, 2008\": \"Memorial Day\",\n",
    "        \"Jul. 4, 2008\": \"Independence Day\",\n",
    "        \"Sep. 1, 2008\": \"Labor Day\",\n",
    "        \"Oct. 13, 2008\": \"Columbus Day\",\n",
    "        \"Nov. 11, 2008\": \"Veterans Day\",\n",
    "        \"Nov. 27, 2008\": \"Thanksgiving\",\n",
    "        \"Dec. 25, 2008\": \"Christmas Day\",\n",
    "        \"Jan. 1, 2009\": \"New Year’s Day\",\n",
    "        \"Jan. 19, 2009\": \"Martin Luther King Jr. Day\",\n",
    "        \"Feb. 16, 2009\": \"Washington’s Birthday\",\n",
    "        \"Mar. 8, 2009\": \"Anomaly day\",\n",
    "    }\n",
    ")\n",
    "false_weekdays = {\n",
    "    \"1\": \"Monday\",\n",
    "    \"2\": \"Tuesday\",\n",
    "    \"3\": \"Wednesday\",\n",
    "    \"4\": \"Thursday\",\n",
    "    \"5\": \"Friday\",\n",
    "    \"6\": \"Saturday\",\n",
    "    \"7\": \"Sunday\",\n",
    "}\n",
    "\n",
    "dates = true_dates if use_true else false_dates\n",
    "anomalies = true_anomalies if use_true else false_anomalies\n",
    "weekdays = true_weekdays if use_true else false_weekdays\n",
    "\n",
    "mask = dates.isin(anomalies)\n",
    "assert sum(mask) == len(anomalies)\n",
    "dates = dates[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c420907-b21b-489b-ba77-3e5523d38ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = pandas.timedelta_range(\"0:00:00\", \"23:59:59\", freq=\"10min\", name=\"time\")\n",
    "assert len(timestamps) == 144\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99944358-4148-462b-bd3d-ce0f1ad0bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reformat(s: str, replacements: dict) -> str:\n",
    "    \"\"\"Replaces substrings with replacments from dict.\n",
    "\n",
    "    https://stackoverflow.com/a/64500851/9318372\n",
    "    \"\"\"\n",
    "    *_, s = (s := s.replace(c, r) for c, r in replacements.items())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a4c59-d906-4da3-9943-22a1e9acaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_file = Traffic.rawdata_path.joinpath(\"PEMS-SF.zip\")\n",
    "\n",
    "with ZipFile(rawdata_file) as files:\n",
    "    with files.open(\"stations_list\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\", \" \": \"\\n\"})\n",
    "        stations = pandas.read_csv(\n",
    "            StringIO(content),\n",
    "            names=[\"station\"],\n",
    "            dtype=\"category\",\n",
    "            squeeze=True,\n",
    "        )\n",
    "\n",
    "    with files.open(\"randperm\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\", \" \": \"\\n\"})\n",
    "        randperm = pandas.read_csv(\n",
    "            StringIO(content),\n",
    "            names=[\"randperm\"],\n",
    "            dtype=\"uint16\",\n",
    "            squeeze=True,\n",
    "        )\n",
    "        randperm = randperm - 1  # we use 0-based indexing\n",
    "        invperm = randperm.copy().argsort()\n",
    "        invperm.name = \"invperm\"\n",
    "        assert (randperm[invperm] == np.arange(len(randperm))).all()\n",
    "\n",
    "    # Shuffle dates according to permutation the authors applied\n",
    "    shuffled_dates = dates[randperm]\n",
    "\n",
    "    with files.open(\"PEMS_trainlabels\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\\n\", \" \": \"\\n\"})\n",
    "        PEMS_trainlabels = pandas.read_csv(\n",
    "            StringIO(content),\n",
    "            names=[\"labels\"],\n",
    "            dtype=\"category\",\n",
    "            squeeze=True,\n",
    "        )\n",
    "        train_dates = shuffled_dates[: len(PEMS_trainlabels)]\n",
    "        PEMS_trainlabels.index = train_dates\n",
    "\n",
    "    # Check that the labels match with the actual weekdays\n",
    "    assert (\n",
    "        PEMS_trainlabels.index.day_name() == PEMS_trainlabels.values.map(weekdays)\n",
    "    ).all(), \"Labels do not match with dates!\"\n",
    "\n",
    "    with files.open(\"PEMS_testlabels\") as file:\n",
    "        content = file.read().decode(\"utf8\")\n",
    "        content = _reformat(content, {\"[\": \"\", \"]\": \"\", \" \": \"\\n\"})\n",
    "        PEMS_testlabels = pandas.read_csv(\n",
    "            StringIO(content),\n",
    "            names=[\"labels\"],\n",
    "            dtype=\"category\",\n",
    "            squeeze=True,\n",
    "        )\n",
    "        test_dates = shuffled_dates[len(PEMS_trainlabels) :]\n",
    "        PEMS_testlabels.index = test_dates\n",
    "\n",
    "    assert (\n",
    "        PEMS_testlabels.index.day_name() == PEMS_testlabels.values.map(weekdays)\n",
    "    ).all(), \"Labels do not match with dates!\"\n",
    "    assert (\n",
    "        PEMS_trainlabels.dtype == PEMS_testlabels.dtype\n",
    "    ), \"Train and test have different labels!\"\n",
    "    PEMS_labels = pandas.concat([PEMS_trainlabels, PEMS_testlabels]).rename(\"labels\")\n",
    "\n",
    "    with files.open(\"PEMS_train\") as file:\n",
    "        _PEMS_train = []\n",
    "        for line in file:\n",
    "            line = line.decode(\"utf8\")\n",
    "            line = _reformat(line, {\"[\": \"\", \"]\": \"\", \";\": \"\\n\", \" \": \",\"})\n",
    "            df = pandas.read_csv(\n",
    "                StringIO(line),\n",
    "                header=None,\n",
    "            )\n",
    "            df = DataFrame(df.values, index=stations, columns=timestamps)\n",
    "            # df.index = stations\n",
    "            # df.columns = timestamps\n",
    "            _PEMS_train.append(df.T)\n",
    "        PEMS_train = pandas.concat(_PEMS_train, keys=train_dates)\n",
    "\n",
    "    with files.open(\"PEMS_test\") as file:\n",
    "        _PEMS_test = []\n",
    "        for line in file:\n",
    "            line = line.decode(\"utf8\")\n",
    "            line = _reformat(line, {\"[\": \"\", \"]\": \"\", \";\": \"\\n\", \" \": \",\"})\n",
    "            df = pandas.read_csv(\n",
    "                StringIO(line),\n",
    "                header=None,\n",
    "            )\n",
    "            df = DataFrame(df.values, index=stations, columns=timestamps)\n",
    "            # df.index = stations\n",
    "            # df.columns = timestamps\n",
    "            _PEMS_test.append(df.T)\n",
    "        PEMS_test = pandas.concat(_PEMS_test, keys=test_dates)\n",
    "\n",
    "PEMS_labels = pandas.concat([PEMS_trainlabels, PEMS_testlabels])\n",
    "\n",
    "mismatches = PEMS_labels[invperm].map(weekdays) != dates.day_name()\n",
    "assert len(dates[mismatches]) == 0, \"Mismatches in label and date weekday!\"\n",
    "PEMS = pandas.concat([PEMS_train, PEMS_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd0850-0c77-428f-aba9-bb815aedcbc6",
   "metadata": {},
   "source": [
    "\n",
    "There are two files for each fold, the data file and the labels file. We have split the 440 time series between train and test folds, but you are of course free to merge them to consider a different cross validation setting.\n",
    "- The PEMS_train textfile has 263 lines. Each line describes a time-series provided as a matrix. The matrix syntax is that of Matlab, e.g. [ a b ; c d] is the matrix with row vectors [a b] and [c d] in that order. Each matrix describes the different occupancies rates (963 lines, one for each station/detector) sampled every 10 minutes during the day (144 columns).\n",
    "- The PEMS_trainlabel text describes, for each day of measurements described above, the day of the week on which the data was sampled, namely an integer between 1 (Mon.) and 7 (Sun.).\n",
    "\n",
    "- PEMS_test and PEMS_testlabels are formatted in the same way, except that there are 173 test instances.\n",
    "\n",
    "- The permutation that I used to shuffle the dataset is given in the randperm file. If you need to rearrange the data so that it follows the calendar order, you should merge train and test samples and reorder them using the inverse permutation of randperm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259eab3c-5d6c-466a-a63f-b68a404adf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.Series(PEMS_testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a015ea9-4174-4736-a21c-2cbb816f7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "PEMS_labels.reset_index().set_index(\"day\").squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5aa339-9538-44db-b5d6-779977d47105",
   "metadata": {},
   "source": [
    "## Example Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdda386-36e2-44bd-aac9-3db75aeeaa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "station = PEMS.loc[dates][\"400000\"].reset_index()\n",
    "station.index = station.day + station.time\n",
    "station = station.drop(columns=[\"day\", \"time\"])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(16, 9), constrained_layout=True)\n",
    "\n",
    "# visualize around anomalies\n",
    "for anomalie, ax in zip(anomalies, axes.flatten()):\n",
    "    start = pandas.Timestamp(anomalie) - pandas.Timedelta(\"2d\")\n",
    "    stop = pandas.Timestamp(anomalie) + pandas.Timedelta(\"2d\")\n",
    "    ts = station.loc[start:stop]\n",
    "    ax.plot(ts.index.to_numpy(), ts.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
