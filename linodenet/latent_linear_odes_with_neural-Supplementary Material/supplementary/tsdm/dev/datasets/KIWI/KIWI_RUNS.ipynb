{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing KIWI dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "Format\n",
    "\n",
    "```python\n",
    "data: tuple[\n",
    "    dict[\n",
    "        'description': set[str],\n",
    "        'variables': list[dict[str, str]],\n",
    "        'time_format': str,\n",
    "        'series': dict[int, \n",
    "            dict['generating_parameters': \n",
    "                 dict[\n",
    "                     'qsmax': float,\n",
    "                     'qm': float,\n",
    "                     'qamax': float,\n",
    "                     'Yem': float,\n",
    "                     'Yxsof': float,\n",
    "                     'Yxa': float,\n",
    "                     'Yos': float,\n",
    "                     'Yoa': float,\n",
    "                     'Yas': float,\n",
    "                     'Kia': float,\n",
    "                     'Ks': float,\n",
    "                     'Ko': float,\n",
    "                     'Kap': float,\n",
    "                     'Kis': float,\n",
    "                     'Ksa': float,\n",
    "                     'Pamax': float,\n",
    "                     'F0': float,\n",
    "                     'mu_set': float,\n",
    "                     'C_feed': float,\n",
    "                     'Kp': float,\n",
    "                ]\n",
    "            ],\n",
    "        ],\n",
    "    ], \n",
    "    dict[int, DataFrame[columns=['X', 'S', 'A', 'DOTm', 'V', 'pulse', 'kLa']]]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity='last_expr_or_assign'  # always print last expr.\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, Interval, Period, Timestamp, Timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Encoding\n",
    "\n",
    "Problem: Columns are encoded in wrong data-types (e.g. categoricals as int or string, floats as string, ints as floats etc.)\n",
    "\n",
    "Solution: Sequentially figure out data types\n",
    "\n",
    "Data Type Hirarchy:\n",
    "1. String-Like (`np.flexible`)\n",
    "    - strings\n",
    "    - bytes\n",
    "2. TimeLike types\n",
    "    - Timestamp (np.datetime64)\n",
    "    - Timedelta (np.timedelta64)\n",
    "3. Numerical (`np.number`)\n",
    "   - floating (`np.floating`)\n",
    "       - float\n",
    "       - complex\n",
    "   - integer (`np.integer`)\n",
    "       - signed\n",
    "       - unsigned\n",
    "4. Boolean (np.bool_)\n",
    "5. Pandas special types\n",
    "    - CategoricalDtype\n",
    "    - DatetimeTZDtype\n",
    "    - PeriodDtype\n",
    "    - IntervalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End goal: whenever it is appropriate to do so, perform the following conversions:\n",
    "\n",
    "1. Get appropriate Nullable Pandas type\n",
    "2. Downcast int → uint\n",
    "3. Downcast int64 → int32 → int16 → int8\n",
    "3. Downcast float64 → float32\n",
    "4. Downcast complex128 → complex64\n",
    "5. Convert to categorical datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdtypes(dtype):\n",
    "    subs = dtype.__subclasses__()\n",
    "    if not subs:\n",
    "        return dtype\n",
    "    return [dtype, [subdtypes(dt) for dt in subs]]\n",
    "\n",
    "\n",
    "subdtypes(np.generic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Format\n",
    "\n",
    "\n",
    "```python\n",
    "dict[int, # run_id\n",
    "    dict[int, # experiment_id\n",
    "         dict[\n",
    "             'metadata',: DataFrame,                # static\n",
    "             'setpoints': DataFrame,                # static\n",
    "             'measurements_reactor',: DataFrame,    # TimeTensor\n",
    "             'measurements_array',: DataFrame,      # TimeTensor\n",
    "             'measurements_aggregated': DataFrame,  # TimeTensor\n",
    "         ]\n",
    "    ]\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw-Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stefans key selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cross_validate_kiwi_runs import ReplicateBasedSplitter, create_replicate_dict\n",
    "\n",
    "with open(\"kiwi_experiments_and_run_355.pk\", \"rb\") as f:\n",
    "    experiments_per_run = pickle.load(f)\n",
    "\n",
    "col_run_to_exp = create_replicate_dict(experiments_per_run)\n",
    "\n",
    "splitter = ReplicateBasedSplitter()\n",
    "\n",
    "for train_keys, test_keys in splitter.split(col_run_to_exp):\n",
    "    data_train = [experiments_per_run[k[0]][k[1]] for k in train_keys]\n",
    "    data_test = [experiments_per_run[k[0]][k[1]] for k in test_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randolf's data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kiwi_experiments_and_run_355.pk\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "col_run_to_exp = create_replicate_dict(data)\n",
    "splitter = ReplicateBasedSplitter()\n",
    "\n",
    "DATA = [\n",
    "    (data[run][exp] | {\"run_id\": run, \"experiment_id\": exp})\n",
    "    for run in data\n",
    "    for exp in data[run]\n",
    "]\n",
    "DF = DataFrame(DATA).set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tables = {}\n",
    "\n",
    "for key in (\n",
    "    \"metadata\",\n",
    "    \"setpoints\",\n",
    "    \"measurements_reactor\",\n",
    "    \"measurements_array\",\n",
    "    \"measurements_aggregated\",\n",
    "):\n",
    "    if key == \"metadata\":\n",
    "        tables[key] = pd.concat(iter(DF[key])).reset_index(drop=True)\n",
    "    else:\n",
    "        tables[key] = (\n",
    "            pd.concat(iter(DF[key]), keys=DF[key].index)\n",
    "            .reset_index(level=2, drop=True)\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_no_information(series) -> bool:\n",
    "    return len(series.dropna().unique()) <= 1\n",
    "\n",
    "\n",
    "def contains_nan_slice(series, slices, two_enough: bool = False) -> bool:\n",
    "    num_missing = 0\n",
    "    for idx in slices:\n",
    "        if pd.isna(series[idx]).all():\n",
    "            num_missing += 1\n",
    "\n",
    "    if (num_missing > 0 and not two_enough) or (\n",
    "        num_missing >= len(slices) - 1 and two_enough\n",
    "    ):\n",
    "        print(f\"{series.name}: data missing in {num_missing}/{len(slices)} slices!\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def float_is_int(series) -> bool:\n",
    "    mask = pd.notna(series)\n",
    "    return series[mask].apply(float.is_integer).all()\n",
    "\n",
    "\n",
    "def is_bool(vals) -> bool:\n",
    "    if len(vals) > 2:\n",
    "        return False\n",
    "\n",
    "    if np.issubdtype(vals.dtype, np.bool_):\n",
    "        print(f\"Boolean column                       : {col}\")\n",
    "        return True\n",
    "    elif np.issubdtype(vals.dtype, np.integer):\n",
    "        # print(vals==0 ^ vals==1)\n",
    "        if ((vals == 0) ^ (vals == 1)).all() or ((vals == -1) ^ (vals == 1)).all():\n",
    "            print(f\"Boolean column pretending to be integer: {col}\")\n",
    "            return Ture\n",
    "    elif np.issubdtype(vals.dtype, np.floating):\n",
    "        if ((vals == 0) ^ (vals == 1)).all() or ((vals == -1) ^ (vals == 1)).all():\n",
    "            print(f\"Boolean column pretending to be float: {col}\")\n",
    "            return True\n",
    "    elif np.issubdtype(vals.dtype, pandas.StringDtype):\n",
    "        val1, val2 = set(vals)\n",
    "        val1 = str(val1).lower()\n",
    "        val2 = str(val2).lower()\n",
    "        if {val1, val2} in (\n",
    "            {\"0\", \"1\"},\n",
    "            {\"-1\", \"+1\"},\n",
    "            {\"-1\", \"1\"},\n",
    "            {\"t\", \"f\"},\n",
    "            {\"true\", \"false\"},\n",
    "            {\"y\", \"n\"},\n",
    "            {\"yes\", \"no\"},\n",
    "        ):\n",
    "            print(f\"Boolean column pretending to be string: {col}\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_true_column_dtypes(table) -> dict[str, str]:\n",
    "    dtypes = {}\n",
    "    for col in table:\n",
    "        series = table[col]\n",
    "        mask = pd.notna(series)\n",
    "        vals = series[mask].unique()\n",
    "\n",
    "\n",
    "def get_boolean_cols(df) -> set[str]:\n",
    "    cols = set()\n",
    "    for col in table:\n",
    "        series = table[col]\n",
    "        mask = pd.notna(series)\n",
    "        vals = series[mask].unique()\n",
    "        if is_bool(vals):\n",
    "            cols.add(col)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def get_integer_cols(table) -> set[str]:\n",
    "    cols = set()\n",
    "    for col in table:\n",
    "        if np.issubdtype(table[col].dtype, np.integer):\n",
    "            print(f\"Integer column                       : {col}\")\n",
    "            cols.add(col)\n",
    "        elif np.issubdtype(table[col].dtype, np.floating) and float_is_int(table[col]):\n",
    "            print(f\"Integer column pretending to be float: {col}\")\n",
    "            cols.add(col)\n",
    "    return cols\n",
    "\n",
    "\n",
    "def get_useless_cols(table, slices, strict: bool = False) -> set[str]:\n",
    "    useless_cols = set()\n",
    "    for col in table:\n",
    "        s = table[col]\n",
    "        if col in (\"run_id\", \"experiment_id\"):\n",
    "            continue\n",
    "        if contains_no_information(s):\n",
    "            print(f\"No information in      {col}\")\n",
    "            useless_cols.add(col)\n",
    "        elif contains_nan_slice(s, slices, two_enough=(not strict)):\n",
    "            print(f\"Missing for some run   {col}\")\n",
    "            useless_cols.add(col)\n",
    "    return useless_cols\n",
    "\n",
    "\n",
    "def get_μ_set(s: str):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = s.strip().lstrip(\"µ_set: \").strip()\n",
    "    percent, s = s.split(\", \")\n",
    "    value = s.strip().rstrip(\"mM IPTG\").strip()\n",
    "    return percent, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MetaData Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = metadata = tables[\"metadata\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "table_columns = set(table.columns)\n",
    "useless_cols = get_useless_cols(table, run_masks) | {\n",
    "    \"folder_id_y\",\n",
    "    \"ph_Base_conc\",\n",
    "    \"ph_Ki\",\n",
    "    \"ph_Kp\",\n",
    "    \"ph_Tolerance\",\n",
    "    \"pms_id\",\n",
    "}\n",
    "integer_cols = get_integer_cols(table)\n",
    "remaining_cols = table_columns - useless_cols;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"Feed_concentration_glc\": \"float32\",\n",
    "    \"OD_Dilution\": \"float32\",\n",
    "    \"bioreactor_id\": \"UInt32\",\n",
    "    \"color\": \"string\",\n",
    "    \"container_number\": \"UInt32\",\n",
    "    \"end_time\": \"datetime64[ns]\",\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"organism_id\": \"UInt32\",\n",
    "    \"pH_correction_factor\": \"float32\",\n",
    "    \"profile_id\": \"UInt32\",\n",
    "    \"profile_name\": \"string\",\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"run_name\": \"string\",\n",
    "    \"start_time\": \"datetime64[ns]\",\n",
    "}\n",
    "\n",
    "categorical_columns = {\n",
    "    \"Feed_concentration_glc\": \"Int16\",\n",
    "    \"OD_Dilution\": \"Float32\",\n",
    "    \"color\": \"category\",\n",
    "    \"pH_correction_factor\": \"Float32\",\n",
    "    \"profile_name\": \"category\",\n",
    "    \"run_name\": \"category\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() >= remaining_cols\n",
    "), f\"Missing encoding: {remaining_cols - selected_columns.keys()}\"\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() <= remaining_cols\n",
    "), f\"Superfluous encoding: {selected_columns.keys() - remaining_cols}\"\n",
    "\n",
    "assert set(categorical_columns) <= set(\n",
    "    selected_columns\n",
    "), f\"Superfluous encoding: {set(categorical_columns) - set(selected_columns)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"bioreactor_id\": \"UInt32\",\n",
    "    \"container_number\": \"UInt32\",\n",
    "    \"profile_id\": \"UInt32\",\n",
    "    \"color\": \"string\",\n",
    "    \"profile_name\": \"string\",\n",
    "    \"organism_id\": \"UInt32\",\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"OD_Dilution\": \"float32\",\n",
    "    \"Feed_concentration_glc\": \"float32\",\n",
    "    \"run_name\": \"string\",\n",
    "    \"pH_correction_factor\": \"float32\",\n",
    "    \"start_time\": \"datetime64[ns]\",\n",
    "    \"end_time\": \"datetime64[ns]\",\n",
    "}\n",
    "\n",
    "categorical_columns = {\n",
    "    \"pH_correction_factor\": \"Float32\",\n",
    "    \"Feed_concentration_glc\": \"Int16\",\n",
    "    \"profile_name\": \"category\",\n",
    "    \"run_name\": \"category\",\n",
    "    \"color\": \"category\",\n",
    "    \"OD_Dilution\": \"Float32\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() >= table_columns - useless_cols\n",
    "), f\"You forgot to check {remaining_cols - selected_columns.keys()}\"\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() <= table_columns - useless_cols\n",
    "), f\"Superfluous {selected_columns.keys() - remaining_cols}\"\n",
    "\n",
    "assert set(categorical_columns) <= set(\n",
    "    selected_columns\n",
    "), f\"Superfluous encoing {set(categorical_columns) - set(selected_columns)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table[selected_columns]\n",
    "table = table.astype(selected_columns)\n",
    "table = table.astype(categorical_columns)\n",
    "metadata = table.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setpoint Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = setpoints = tables[\"setpoints\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "table_columns = set(table.columns)\n",
    "useless_cols = get_useless_cols(table, run_masks)\n",
    "integer_cols = get_integer_cols(table)\n",
    "remaining_cols = table_columns - useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpoints[\"unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"cultivation_age\": \"UInt32\",\n",
    "    \"setpoint_id\": \"UInt32\",\n",
    "    \"unit\": \"string\",\n",
    "    # \"Puls_AceticAcid\": \"Float32\",\n",
    "    \"Puls_Glucose\": \"Float32\",\n",
    "    # \"Puls_Medium\": \"Float32\",\n",
    "    \"StirringSpeed\": \"UInt16\",\n",
    "    # \"pH\": \"Float32\",\n",
    "    \"Feed_glc_cum_setpoints\": \"UInt16\",\n",
    "    \"Flow_Air\": \"UInt8\",\n",
    "    \"InducerConcentration\": \"Float32\",\n",
    "    # \"Flow_Nitrogen\": \"Float32\",\n",
    "    # \"Flow_O2\": \"Float32\",\n",
    "    # \"Feed_dextrine_cum_setpoints\": \"Float32\",\n",
    "}\n",
    "\n",
    "categorical_columns = {\n",
    "    \"unit\": \"category\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() >= table_columns - useless_cols\n",
    "), f\"You forgot to check {remaining_cols - selected_columns.keys()}\"\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() <= table_columns - useless_cols\n",
    "), f\"Superfluous {selected_columns.keys() - remaining_cols}\"\n",
    "\n",
    "assert set(categorical_columns) <= set(\n",
    "    selected_columns\n",
    "), f\"Superfluous encoing {set(categorical_columns) - set(selected_columns)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"unit\"] = table[\"unit\"].replace(to_replace=\"-\", value=pd.NA)\n",
    "table = table[selected_columns]\n",
    "table = table.astype(selected_columns)\n",
    "table = table.astype(categorical_columns)\n",
    "setpoints = table.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Measurements Reactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = reactor = tables[\"measurements_reactor\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "table_columns = set(table.columns)\n",
    "useless_cols = get_useless_cols(table, run_masks)\n",
    "integer_cols = get_integer_cols(table)\n",
    "remaining_cols = table_columns - useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"Acetate\": \"Float32\",\n",
    "    \"Base\": \"Int16\",\n",
    "    \"Cumulated_feed_volume_glucose\": \"Int16\",\n",
    "    \"Cumulated_feed_volume_medium\": \"Float32\",\n",
    "    \"DOT\": \"Float32\",\n",
    "    \"Fluo_GFP\": \"Float32\",\n",
    "    \"Glucose\": \"Float32\",\n",
    "    \"InducerConcentration\": \"Float32\",\n",
    "    \"OD600\": \"Float32\",\n",
    "    \"Probe_Volume\": \"Int16\",\n",
    "    \"Volume\": \"Float32\",\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"measurement_id\": \"UInt32\",\n",
    "    \"measurement_time\": \"datetime64[ns]\",\n",
    "    \"pH\": \"Float32\",\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"unit\": \"string\",\n",
    "}\n",
    "\n",
    "categorical_columns = {\n",
    "    \"unit\": \"category\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() >= table_columns - useless_cols\n",
    "), f\"You forgot to check {remaining_cols - selected_columns.keys()}\"\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() <= table_columns - useless_cols\n",
    "), f\"Superfluous {selected_columns.keys() - remaining_cols}\"\n",
    "\n",
    "assert set(categorical_columns) <= set(\n",
    "    selected_columns\n",
    "), f\"Superfluous encoing {set(categorical_columns) - set(selected_columns)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"unit\"] = table[\"unit\"].replace(to_replace=\"-\", value=pd.NA)\n",
    "table = table[selected_columns]\n",
    "table = table.astype(selected_columns)\n",
    "table = table.astype(categorical_columns)\n",
    "reactor = table.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements_Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = array = tables[\"measurements_array\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "table_columns = set(table.columns)\n",
    "useless_cols = get_useless_cols(table, run_masks)\n",
    "integer_cols = get_integer_cols(table)\n",
    "remaining_cols = table_columns - useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"measurement_time\": \"datetime64[ns]\",\n",
    "    \"measurement_id\": \"UInt32\",\n",
    "    \"unit\": \"string\",\n",
    "    \"Flow_Air\": \"Float32\",\n",
    "    # \"Flow_Nitrogen\"      :         \"float64\",\n",
    "    # \"Flow_O2\"            :         \"float64\",\n",
    "    \"StirringSpeed\": \"Int16\",\n",
    "    \"Temperature\": \"Float32\",\n",
    "}\n",
    "\n",
    "categorical_columns = {\n",
    "    \"unit\": \"category\",\n",
    "}\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() >= table_columns - useless_cols\n",
    "), f\"You forgot to check {remaining_cols - selected_columns.keys()}\"\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() <= table_columns - useless_cols\n",
    "), f\"Superfluous {selected_columns.keys() - remaining_cols}\"\n",
    "\n",
    "assert set(categorical_columns) <= set(\n",
    "    selected_columns\n",
    "), f\"Superfluous encoing {set(categorical_columns) - set(selected_columns)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"unit\"] = table[\"unit\"].replace(to_replace=\"-\", value=pd.NA)\n",
    "table = table[selected_columns]\n",
    "table = table.astype(selected_columns)\n",
    "table = table.astype(categorical_columns)\n",
    "array = table.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.dropna(how=\"all\").groupby([\"run_id\", \"experiment_id\", \"measurement_time\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements Aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = aggregated = tables[\"measurements_aggregated\"]\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "table_columns = set(table.columns)\n",
    "useless_cols = get_useless_cols(table, run_masks)\n",
    "integer_cols = get_integer_cols(table)\n",
    "remaining_cols = table_columns - useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"run_id\": \"UInt32\",\n",
    "    \"experiment_id\": \"UInt32\",\n",
    "    \"measurement_time\": \"datetime64[ns]\",\n",
    "    \"unit\": \"string\",\n",
    "    \"Flow_Air\": \"Float32\",\n",
    "    # \"Flow_Nitrogen\"                 :          \"Float32\",\n",
    "    # \"Flow_O2\"                       :          \"Int32\",\n",
    "    \"StirringSpeed\": \"Int16\",\n",
    "    \"Temperature\": \"Float32\",\n",
    "    \"Acetate\": \"Float32\",\n",
    "    # \"Acid\"                          :          \"Float32\",\n",
    "    \"Base\": \"Int16\",\n",
    "    \"Cumulated_feed_volume_glucose\": \"Int16\",\n",
    "    \"Cumulated_feed_volume_medium\": \"Float32\",\n",
    "    \"DOT\": \"Float32\",\n",
    "    # \"Fluo_CFP\"                      :          \"Float32\",\n",
    "    # \"Fluo_RFP\"                      :          \"Float32\",\n",
    "    # \"Fluo_YFP\"                      :          \"Float32\",\n",
    "    \"Glucose\": \"Float32\",\n",
    "    \"OD600\": \"Float32\",\n",
    "    \"Probe_Volume\": \"Int16\",\n",
    "    \"pH\": \"Float32\",\n",
    "    \"Fluo_GFP\": \"Float32\",\n",
    "    \"InducerConcentration\": \"Float32\",\n",
    "    # \"remark\"                        :           \"string\",\n",
    "    \"Volume\": \"Float32\",\n",
    "}\n",
    "\n",
    "categorical_columns = {\"unit\": \"category\"}\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() >= table_columns - useless_cols\n",
    "), f\"You forgot to check {remaining_cols - selected_columns.keys()}\"\n",
    "\n",
    "assert (\n",
    "    selected_columns.keys() <= table_columns - useless_cols\n",
    "), f\"Superfluous {selected_columns.keys() - remaining_cols}\"\n",
    "\n",
    "assert set(categorical_columns) <= set(\n",
    "    selected_columns\n",
    "), f\"Superfluous encoing {set(categorical_columns) - set(selected_columns)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[\"unit\"] = table[\"unit\"].replace(to_replace=\"-\", value=pd.NA)\n",
    "# aggregated = aggregated.astype(aggregated_dtypes)\n",
    "# aggregated = aggregated.astype(aggregated_categoricals)\n",
    "table = table[selected_columns].astype(selected_columns)\n",
    "aggregated = table.set_index([\"run_id\", \"experiment_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = aggregated.copy()\n",
    "table = table.drop(columns=\"unit\")\n",
    "table = table.groupby([\"run_id\", \"experiment_id\", \"measurement_time\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table.astype(\"float32\")\n",
    "table = table.reset_index()\n",
    "table = table.astype(\"float32\")\n",
    "\n",
    "runs = table[\"run_id\"].dropna().unique()\n",
    "run_masks = [table[\"run_id\"] == run for run in runs]\n",
    "\n",
    "table_columns = set(table.columns)\n",
    "useless_cols = get_useless_cols(table, run_masks)\n",
    "integer_cols = get_integer_cols(table)\n",
    "remaining_cols = table_columns - useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated.drop(columns=\"unit\").groupby(\n",
    "    [\"run_id\", \"experiment_id\", \"measurement_time\"]\n",
    ").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdm.datasets.KIWI_RUNS.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsdm.datasets.KIWI_RUNS.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.tasks import KIWI_RUNS_TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = KIWI_RUNS_TASK()\n",
    "task.split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, md = task.splits((2, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsdm.datasets import KIWI_RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KIWI_RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = KIWI_RUNS.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove run_id 355\n",
    "md = md.drop(355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now there are no missing values!\n",
    "pandas.isna(md).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# almost all data is highly compressible.\n",
    "Series({col: len(md[col].unique()) for col in md})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(md).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regarding  # We see that profile_id is useless however, since\n",
    "# it is a categorical that is different for every input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len]KIWI_RUNS.metadata[\"profile_name\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed_concentration_glc             Int16 → convert to float\n",
    "OD_Dilution                      Float32 → keep as-is\n",
    "bioreactor_id                     UInt32 → drop / One-Hot\n",
    "color                           category → drop / One-Hot\n",
    "container_number                  UInt32 → drop\n",
    "end_time                  datetime64[ns] → drop, but use for time-scaling\n",
    "organism_id                       UInt32 → One-Hot\n",
    "pH_correction_factor             Float32 → keep as-is\n",
    "profile_id                        UInt32 → drop\n",
    "profile_name                    category → drop\n",
    "run_name                        category → drop\n",
    "start_time                datetime64[ns] → drop, but use for time-scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
