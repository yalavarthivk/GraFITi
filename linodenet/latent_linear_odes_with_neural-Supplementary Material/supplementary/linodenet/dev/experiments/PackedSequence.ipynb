{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac269a48-80dd-424b-8dd1-2cfd8458c2df",
   "metadata": {},
   "source": [
    "# Efficient TS batching via PackedSequence\n",
    "\n",
    "\n",
    "<https://discuss.pytorch.org/t/customized-rnn-cell-which-can-accept-packsequence/1067>\n",
    "\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc58cb4-80cc-446d-a30c-e5a8ab89041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import (\n",
    "    pack_sequence,\n",
    "    pad_sequence,\n",
    "    pack_padded_sequence,\n",
    "    pad_packed_sequence,\n",
    "    PackedSequence,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60c3df-17e6-4316-a1ab-422e9591a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(sequence: list[torch.Tensor], **kwargs) -> tuple[PackedSequence, list[int]]:\n",
    "    lengths = list(map(len, sequence))\n",
    "    tensors = [tensor for length, tensor in zip(lengths, sequence) if length > 0]\n",
    "    packed_sequence = pack_sequence(tensors, **kwargs)\n",
    "    return packed_sequence, lengths\n",
    "\n",
    "\n",
    "def unpack(packed_sequence: PackedSequence, lengths: list[int]) -> list[torch.Tensor]:\n",
    "    device = packed_sequence.data.device\n",
    "    dtype = packed_sequence.data.dtype\n",
    "    trailing_dims = packed_sequence.data.shape[1:]\n",
    "    unpacked_sequence = []\n",
    "    idx_map = {}\n",
    "    head = 0\n",
    "    for b_idx, length in enumerate(lengths):\n",
    "        unpacked_sequence.append(\n",
    "            torch.zeros(length, *trailing_dims, device=device, dtype=dtype)\n",
    "        )\n",
    "        if length > 0:\n",
    "            idx_map[head] = b_idx\n",
    "            head += 1\n",
    "    head = 0\n",
    "    for l_idx, b_size in enumerate(packed_sequence.batch_sizes):\n",
    "        for b_idx in range(b_size):\n",
    "            unpacked_sequence[idx_map[b_idx]][l_idx] = packed_sequence.data[head]\n",
    "            head += 1\n",
    "    return unpacked_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28ff07-4b7d-467d-8c68-4c5249e2115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation\n",
    "batch_size = 32\n",
    "input_size = 100\n",
    "hidden_size = 512\n",
    "seq_len_range = (10, 1000)\n",
    "num_batches = 10\n",
    "\n",
    "rnn = nn.RNN(input_size, hidden_size, num_layers=4, bias=True, batch_first=True)\n",
    "rnn.to(device)\n",
    "rnn.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6971884-2ea8-484c-9a71-f1ccc16011ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "batches = list()\n",
    "for idx in range(num_batches):\n",
    "    batch = []\n",
    "    for k in range(batch_size):\n",
    "        rand_len = np.random.randint(*seq_len_range)\n",
    "        x = torch.rand((rand_len, input_size), device=device)\n",
    "        y = torch.rand((rand_len, hidden_size), device=device)\n",
    "        batch += [(x, y)]\n",
    "    batch = sorted(batch, key=lambda x: x[0].size(0), reverse=True)\n",
    "    batches += [batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43575b-b819-4c5f-a63a-883e7720b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for padded input\n",
    "start = time.time()\n",
    "for batch in batches:\n",
    "    yhat = []\n",
    "    l = torch.tensor(0, dtype=dtype, device=device)\n",
    "    for x, y in batch:\n",
    "        yhat = rnn(x.unsqueeze(0))[0].squeeze(dim=0)\n",
    "        r = (y - yhat) ** 2\n",
    "        l += torch.sum(r)\n",
    "    l.backward()\n",
    "    g = torch.cat([w.grad.flatten() for w in rnn.parameters()])\n",
    "    rnn.zero_grad()\n",
    "end = time.time()\n",
    "print(f\"elapsed time for padded input: {end - start} secs\")\n",
    "print(torch.sum(torch.isnan(g)))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0998cec6-6524-4295-8b9a-f06c8614b750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for padded input\n",
    "start = time.time()\n",
    "for batch in batches:\n",
    "    x, y = zip(*batch)\n",
    "    x = pad_sequence(x, padding_value=np.nan, batch_first=True)\n",
    "    y = pad_sequence(y, padding_value=np.nan, batch_first=True)\n",
    "    yhat = rnn(x)[0]\n",
    "    mask = torch.isnan(yhat)\n",
    "    zero = torch.tensor(0, dtype=dtype, device=device)\n",
    "    r = torch.where(mask, zero, (y - yhat) ** 2)\n",
    "    l = torch.sum(r)\n",
    "    l.backward()\n",
    "    g = torch.cat([w.grad.flatten() for w in rnn.parameters()])\n",
    "    rnn.zero_grad()\n",
    "end = time.time()\n",
    "print(f\"elapsed time for padded input: {end - start} secs\")\n",
    "print(torch.sum(torch.isnan(g)))\n",
    "print(r.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a0db5-ae1b-4bed-8b93-cb774aa70f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for packed input\n",
    "start = time.time()\n",
    "for batch in batches:\n",
    "    x, y = zip(*batch)\n",
    "    x = pack_sequence(x)\n",
    "    y = pack_sequence(y)\n",
    "    yhat = rnn(x)[0]\n",
    "    r = (y.data - yhat.data) ** 2\n",
    "    l = torch.sum(r)\n",
    "    l.backward()\n",
    "    g = torch.cat([w.grad.flatten() for w in rnn.parameters()])\n",
    "    rnn.zero_grad()\n",
    "end = time.time()\n",
    "print(f\"elapsed time for packed input: {end - start} secs\")\n",
    "print(torch.sum(torch.isnan(g)))\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546727f4-4ead-4520-9cb2-49ea696c2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for packed input with unpack\n",
    "start = time.time()\n",
    "for batch in batches:\n",
    "    x_batch, y_batch = zip(*batch)\n",
    "    x_packed, _ = pack(x_batch)\n",
    "    y_packed, lengths = pack(y_batch)\n",
    "    yhat_packed = rnn(x_packed)[0]\n",
    "\n",
    "    r = torch.tensor(0, dtype=dtype, device=device)\n",
    "    for y, yhat in zip(y_batch, unpack(y_packed, lengths)):\n",
    "        r += torch.mean((y - yhat) ** 2)\n",
    "    r.backward()\n",
    "    g = torch.cat([w.grad.flatten() for w in rnn.parameters()])\n",
    "    print(torch.sum(torch.isnan(g)))\n",
    "    rnn.zero_grad()\n",
    "end = time.time()\n",
    "print(f\"elapsed time for packed input: {end - start} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b8e62-8f32-4280-bbb4-81986c6909de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device(\"cpu\")\n",
    "rnn = nn.RNN(2, 2, num_layers=4, bias=True, batch_first=True)\n",
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffe958-d2a0-4553-97e8-01842ecc91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(np.random.randint(0, 9, (5, 2)), dtype=dtype, device=device)\n",
    "b = torch.tensor(np.random.randint(0, 9, (4, 2)), dtype=dtype, device=device)\n",
    "c = torch.tensor(np.random.randint(0, 9, (3, 2)), dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f603d97f-07b2-4882-a907-303ec4bd73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [a, b, c]\n",
    "lengths = [len(x) for x in batch]\n",
    "x, lengths = pack([a, b, c])\n",
    "rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b837b1-ffb8-4909-9c7d-8123845203c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rnn(x)[0]\n",
    "y = unpack(y, lengths)\n",
    "yhat = [rnn(z.unsqueeze(dim=0))[0] for z in batch]\n",
    "[z - zhat for z, zhat in zip(y, yhat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06575167-4fef-4e5a-bf3f-102b5210d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = pad_sequence(batch, padding_value=np.nan, batch_first=True)\n",
    "rnn(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53d94c-07e0-49fc-b023-09d70b138ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
